{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "\n",
    "def extract_data(df, i):\n",
    "\n",
    "    # get image info\n",
    "    data_row = df['data_row'][i]\n",
    "    Data_row_id = data_row['id']\n",
    "    global_key = data_row['global_key']\n",
    "    img_link = data_row['row_data']\n",
    "\n",
    "    media_attributes = df['media_attributes'][i]\n",
    "    try:\n",
    "        height = media_attributes['height']\n",
    "        width = media_attributes['width']\n",
    "    except:\n",
    "        height = ''\n",
    "        width = ''\n",
    "\n",
    "    # get annotation info\n",
    "    project = df['projects'][i]\n",
    "    key = list(project.keys())[0]\n",
    "    info = project[key]\n",
    "\n",
    "    annotator_email = info['labels'][0]['label_details']['created_by']\n",
    "\n",
    "    try:\n",
    "        feature_id = info['labels'][0]['annotations']['classifications'][0]['feature_id']\n",
    "        annotations = info['labels'][0]['annotations']['classifications'][0]['text_answer']['content']\n",
    "    except:\n",
    "        feature_id = ''\n",
    "        annotations = ''\n",
    "\n",
    "    return [Data_row_id, global_key, img_link, height, width, feature_id, annotator_email, annotations]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndjson has 6702 rows of data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing rows from 0 to 10: 100%|███████████████████████████████| 10/10 [00:00<00:00, 5997.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing first 5 rows of the simplified dataframe:\n",
      "                 Data_row_id     global_key  \\\n",
      "0  clj89jr2p08ts0720cx160wxu   batch-3:7689   \n",
      "1  clj89jr2p08tw0720dw722u8u   batch-3:7691   \n",
      "2  clj89jr2p1uni078pggej5npj  batch-3:11014   \n",
      "3  clj89jr2p1unm078pa7evh5rp  batch-3:11015   \n",
      "4  clj89jr2p1unq078p59b4aq0e  batch-3:11016   \n",
      "\n",
      "                                            img_link  height  width  \\\n",
      "0  https://images-na.ssl-images-amazon.com/images...    1856   1229   \n",
      "1  https://www.litres.ru/static/bookimages/40/62/...    1960   1400   \n",
      "2  https://images-na.ssl-images-amazon.com/images...    2444   1642   \n",
      "3  https://image.isu.pub/180226193328-0cd01d7ef1d...    1496   1156   \n",
      "4  https://dqzrr9k4bjpzk.cloudfront.net/images/12...    2818   2818   \n",
      "\n",
      "                  feature_id          annotator_email  \\\n",
      "0  cljlhjhgw000f356lhji83sow  caparisonsoft@gmail.com   \n",
      "1  cljlhr6zd000i356mmtrih7i8        kgtieku@gmail.com   \n",
      "2  cljli159g0001356mpv1yd0jt        kgtieku@gmail.com   \n",
      "3  cljliy98i0001356m915viqfd        kgtieku@gmail.com   \n",
      "4  cljlj193n0002356mfbnurngv        kgtieku@gmail.com   \n",
      "\n",
      "                                         annotations  \n",
      "0  This is the cover of an album 'Say It Loud! A ...  \n",
      "1  The title displayed on this cover is \"Waterman...  \n",
      "2  The title displayed on this cover is \"The Phil...  \n",
      "3  The title displayed on this cover is \"The Star...  \n",
      "4  The title displayed on this cover is \"Clyde: T...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "records = map(json.loads, open('./export_ndjson/export-result (1).ndjson'))\n",
    "df = pd.DataFrame.from_records(records)\n",
    "n_row = df.shape[0]\n",
    "values = []\n",
    "start, end = 0, 10\n",
    "print(f'ndjson has {n_row} rows of data.')\n",
    "\n",
    "for i in tqdm(range(start, end), desc=f'processing rows from {start} to {end}', total=end-start, ncols=100):\n",
    "    \n",
    "    # extract info\n",
    "    [Data_row_id, global_key, img_link, height, width, feature_id, annotator_email, annotations] = extract_data(df, i)\n",
    "    values.append([Data_row_id, global_key, img_link, height, width, feature_id, annotator_email, annotations])\n",
    "    \n",
    "    # download image using the URL\n",
    "    if f'{Data_row_id}.jpg' not in os.listdir('./img'):\n",
    "        try:\n",
    "            img_data = requests.get(img_link).content\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        with open(f'./img/{Data_row_id}.jpg', 'wb') as handler:\n",
    "            handler.write(img_data)\n",
    "\n",
    "# create a new data frame\n",
    "df_simplify = pd.DataFrame(data=values, columns=['Data_row_id', 'global_key', 'img_link',\n",
    "                                            'height', 'width', 'feature_id', \n",
    "                                            'annotator_email', 'annotations'])\n",
    "\n",
    "print('showing first 5 rows of the simplified dataframe:')\n",
    "print(df_simplify[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Doing OCR: 100%|████████████████████████████████████████████████████| 11/11 [00:22<00:00,  2.01s/it]\n"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "import numpy as np\n",
    "import imageio\n",
    "os.environ['http_proxy'] = 'http://127.0.0.1:7890'\n",
    "os.environ['https_proxy'] = 'https://127.0.0.1:7890'\n",
    "import pickle as pk\n",
    "\n",
    "# Detect English only. (easier to do text matching)\n",
    "reader = easyocr.Reader(['en'], gpu=True)\n",
    "# Detect Chinese too. However, the labeler might not be able to write chinese characters.\n",
    "# reader = easyocr.Reader(['ch_sim', 'en'], gpu=True)\n",
    "\n",
    "ocr_dict = dict()\n",
    "file_list = sorted(os.listdir('./img/'))\n",
    "for i, name in tqdm(enumerate(file_list), desc=f'Doing OCR', total=len(file_list), ncols=100):\n",
    "    if name.endswith('jpg'):\n",
    "        try:\n",
    "            img = np.asarray(imageio.v2.imread(f'./img/{name}'))\n",
    "            w, h = img.shape[0], img.shape[1]\n",
    "            result = reader.readtext(f'./img/{name}', paragraph=False, detail=True)\n",
    "            ocr_dict[name] = [[w, h], result]\n",
    "\n",
    "        except:\n",
    "            print(f'ERROR!! skip: {name}')\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two functions for text quality filtering and text matching\n",
    "def ocr_process(ocr):\n",
    "\n",
    "    w, h = ocr[0]\n",
    "    text_info = ocr[1]\n",
    "    out_text = []\n",
    "\n",
    "    for info in text_info:\n",
    "\n",
    "        confidence = float(info[2])\n",
    "        text = info[1]\n",
    "        bbox = np.array(info[0])\n",
    "        wb_max, hb_max = np.max(bbox, axis=0)\n",
    "        wb_min, hb_min = np.min(bbox, axis=0)\n",
    "        wb = wb_max - wb_min\n",
    "        hb = hb_max - hb_min\n",
    "\n",
    "        h_ratio = hb/h\n",
    "\n",
    "        if confidence < 0.1 or len(text) < 3 or h_ratio < 0.05:\n",
    "            continue\n",
    "        else:\n",
    "            out_text.append(text)\n",
    "\n",
    "    return out_text\n",
    "\n",
    "\n",
    "# dynamic programming for approximate text matching. (based on edit distance)\n",
    "def text_match(detected_text, annotation):\n",
    "\n",
    "    detected_text = str(detected_text).lower()\n",
    "    annotation = str(annotation).lower()\n",
    "\n",
    "    l1 = len(detected_text)\n",
    "    l2 = len(annotation)\n",
    "    T = np.zeros([l1+1, l2+1])\n",
    "    T[:, 0] = [i for i in range(l1+1)]\n",
    "\n",
    "    for i in range(1, l1+1):\n",
    "        for j in range(1, l2+1):\n",
    "\n",
    "            if detected_text[i-1] == annotation[j-1]:\n",
    "                T[i, j] = T[i-1, j-1]\n",
    "            else:\n",
    "                T[i, j] = min(T[i-1, j], T[i, j-1]) + 1\n",
    "\n",
    "    return 1 - min(T[-1, :]) / l1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 209.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing first 5 rows of the simplified dataframe:\n",
      "  OCR_review                Data_row_id     global_key  \\\n",
      "0       good  clj89jr2p08ts0720cx160wxu   batch-3:7689   \n",
      "1       good  clj89jr2p08tw0720dw722u8u   batch-3:7691   \n",
      "2       good  clj89jr2p1uni078pggej5npj  batch-3:11014   \n",
      "3       good  clj89jr2p1unm078pa7evh5rp  batch-3:11015   \n",
      "4       good  clj89jr2p1unq078p59b4aq0e  batch-3:11016   \n",
      "\n",
      "                                            img_link  height  width  \\\n",
      "0  https://images-na.ssl-images-amazon.com/images...    1856   1229   \n",
      "1  https://www.litres.ru/static/bookimages/40/62/...    1960   1400   \n",
      "2  https://images-na.ssl-images-amazon.com/images...    2444   1642   \n",
      "3  https://image.isu.pub/180226193328-0cd01d7ef1d...    1496   1156   \n",
      "4  https://dqzrr9k4bjpzk.cloudfront.net/images/12...    2818   2818   \n",
      "\n",
      "                  feature_id          annotator_email  \\\n",
      "0  cljlhjhgw000f356lhji83sow  caparisonsoft@gmail.com   \n",
      "1  cljlhr6zd000i356mmtrih7i8        kgtieku@gmail.com   \n",
      "2  cljli159g0001356mpv1yd0jt        kgtieku@gmail.com   \n",
      "3  cljliy98i0001356m915viqfd        kgtieku@gmail.com   \n",
      "4  cljlj193n0002356mfbnurngv        kgtieku@gmail.com   \n",
      "\n",
      "                                         annotations  \\\n",
      "0  This is the cover of an album 'Say It Loud! A ...   \n",
      "1  The title displayed on this cover is \"Waterman...   \n",
      "2  The title displayed on this cover is \"The Phil...   \n",
      "3  The title displayed on this cover is \"The Star...   \n",
      "4  The title displayed on this cover is \"Clyde: T...   \n",
      "\n",
      "                                        ocr_selected  \n",
      "0  [LOUDI, BLACK, Celebration, MUSIC |, America, ...  \n",
      "1  [WATERMAN, AMY (LANE), A LITTLE PRESERVING, BO...  \n",
      "2  [LAWRENCE, KOHLBERG, Moral Development, VOLUME...  \n",
      "3  [THE, STARGATE, CONSPIRACY, Lynn, and the Myst...  \n",
      "4  [CLYDE:, THe CAT THAT Came INFRom THe cold, DA...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Do text filtering and matching\n",
    "\n",
    "OCR_review = []\n",
    "ocr_selected = []\n",
    "for i, (name, annotation) in tqdm(enumerate(zip(df_simplify['Data_row_id'], df_simplify['annotations'])), total=df_simplify.shape[0], ncols=100):\n",
    "\n",
    "    try:\n",
    "        ocr = ocr_dict[f'{name}.jpg']\n",
    "        detected_text = ocr_process(ocr)\n",
    "        match_score_sum = 0\n",
    "        total_l = 0\n",
    "        for text in detected_text:\n",
    "            match_score_sum += text_match(text, annotation) * len(text)\n",
    "            total_l += len(text)\n",
    "\n",
    "        r = match_score_sum / total_l\n",
    "\n",
    "    except:\n",
    "        OCR_review.append('error')\n",
    "        ocr_selected.append('')\n",
    "        continue\n",
    "\n",
    "    if r < 0.8:\n",
    "        OCR_review.append('no')\n",
    "    else:\n",
    "        OCR_review.append('good')\n",
    "\n",
    "    ocr_selected.append(detected_text)\n",
    "\n",
    "\n",
    "df_simplify['ocr_selected'] = ocr_selected\n",
    "\n",
    "if 'OCR_review' not in df_simplify.columns:\n",
    "    df_simplify.insert(loc=0, column='OCR_review', value=OCR_review)\n",
    "else:\n",
    "    df_simplify['OCR_review'] = OCR_review\n",
    "\n",
    "print('showing first 5 rows of the simplified dataframe:')\n",
    "print(df_simplify[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "import imageio\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "# get clip text embedding for sentences\n",
    "def get_text_embeds(sentences, model):\n",
    "\n",
    "    text = clip.tokenize(sentences).to(device)\n",
    "    text_features = model.encode_text(text).to(torch.float)\n",
    "\n",
    "    return text_features\n",
    "\n",
    "# learn the best linear combination of sentence embeddings that approximate the image embedding.\n",
    "def select_sentence(text_features, image_features):\n",
    "\n",
    "    n = text_features.shape[0]\n",
    "    device = text_features.device\n",
    "    w = torch.nn.Parameter(torch.ones([n, 1]).to(device))\n",
    "    optimizer = optim.Adam([w], lr=0.001, weight_decay=0.0, betas=(0.9, 0.999), amsgrad=False,\n",
    "                           eps=1e-08)\n",
    "    cos_sim = torch.nn.CosineSimilarity(dim=1)\n",
    "\n",
    "    for _ in range(1000):\n",
    "        w1 = torch.relu(w)\n",
    "        y = text_features.detach() * w1\n",
    "        y = torch.sum(y, dim=0)\n",
    "        loss = 1 - cos_sim(image_features.detach(), y) + torch.norm(w, p=1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_([w], 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:03<00:00,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing first 5 rows of the simplified dataframe:\n",
      "   CLIP_cosine OCR_review                Data_row_id     global_key  \\\n",
      "0     0.700348       good  clj89jr2p08ts0720cx160wxu   batch-3:7689   \n",
      "1     0.664635       good  clj89jr2p08tw0720dw722u8u   batch-3:7691   \n",
      "2     0.660056       good  clj89jr2p1uni078pggej5npj  batch-3:11014   \n",
      "3     0.667256       good  clj89jr2p1unm078pa7evh5rp  batch-3:11015   \n",
      "4     0.668083       good  clj89jr2p1unq078p59b4aq0e  batch-3:11016   \n",
      "\n",
      "                                            img_link  height  width  \\\n",
      "0  https://images-na.ssl-images-amazon.com/images...    1856   1229   \n",
      "1  https://www.litres.ru/static/bookimages/40/62/...    1960   1400   \n",
      "2  https://images-na.ssl-images-amazon.com/images...    2444   1642   \n",
      "3  https://image.isu.pub/180226193328-0cd01d7ef1d...    1496   1156   \n",
      "4  https://dqzrr9k4bjpzk.cloudfront.net/images/12...    2818   2818   \n",
      "\n",
      "                  feature_id          annotator_email  \\\n",
      "0  cljlhjhgw000f356lhji83sow  caparisonsoft@gmail.com   \n",
      "1  cljlhr6zd000i356mmtrih7i8        kgtieku@gmail.com   \n",
      "2  cljli159g0001356mpv1yd0jt        kgtieku@gmail.com   \n",
      "3  cljliy98i0001356m915viqfd        kgtieku@gmail.com   \n",
      "4  cljlj193n0002356mfbnurngv        kgtieku@gmail.com   \n",
      "\n",
      "                                         annotations  \\\n",
      "0  This is the cover of an album 'Say It Loud! A ...   \n",
      "1  The title displayed on this cover is \"Waterman...   \n",
      "2  The title displayed on this cover is \"The Phil...   \n",
      "3  The title displayed on this cover is \"The Star...   \n",
      "4  The title displayed on this cover is \"Clyde: T...   \n",
      "\n",
      "                                        ocr_selected  \n",
      "0  [LOUDI, BLACK, Celebration, MUSIC |, America, ...  \n",
      "1  [WATERMAN, AMY (LANE), A LITTLE PRESERVING, BO...  \n",
      "2  [LAWRENCE, KOHLBERG, Moral Development, VOLUME...  \n",
      "3  [THE, STARGATE, CONSPIRACY, Lynn, and the Myst...  \n",
      "4  [CLYDE:, THe CAT THAT Came INFRom THe cold, DA...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model, preprocess = clip.load('ViT-B/32', device, jit=False)\n",
    "\n",
    "cos_sim = []\n",
    "for i, (name, annotation) in tqdm(enumerate(zip(df_simplify['Data_row_id'], df_simplify['annotations'])), total=df_simplify.shape[0], ncols=150):\n",
    "\n",
    "    try:\n",
    "        image = preprocess(Image.open(f'./img/{name}.jpg')).unsqueeze(0).to(device)\n",
    "        image_features = model.encode_image(image).to(torch.float)\n",
    "        text_features = get_text_embeds(annotation.split('.'), model)\n",
    "\n",
    "        d = select_sentence(text_features, image_features)\n",
    "        cos_sim.append(d)\n",
    "\n",
    "    except:\n",
    "        cos_sim.append(torch.nan)\n",
    "        continue\n",
    "        \n",
    "if 'CLIP_cosine' not in df_simplify.columns:\n",
    "    df_simplify.insert(loc=0, column='CLIP_cosine', value=cos_sim)\n",
    "else:\n",
    "    df_simplify['CLIP_cosine'] = cos_sim\n",
    "\n",
    "print('showing first 5 rows of the simplified dataframe:')\n",
    "print(df_simplify[:5])\n",
    "\n",
    "df_simplify.to_csv('./review.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-2ef7a707",
   "language": "python",
   "display_name": "PyCharm (layout-dm)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}